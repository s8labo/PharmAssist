<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Talking Head with Azure TTS</title>
  <style>
    body, html { 
      width: 100%; 
      height: 100%; 
      max-width: 800px; 
      margin: auto; 
      position: relative; 
      background-color: dimgray; 
      color: white;
    }
    #avatar { 
      display: block; 
      width: 100%; 
      height: 100%;
    }
    #controls { 
      display: block; 
      position: absolute; 
      top: 10px; 
      left: 10px; 
      right: 10px; 
      height: 50px;
    }
    #text { 
      position: absolute; 
      width: Calc(100% - 110px); 
      height: 100%; 
      top: 0; 
      left: 0; 
      bottom: 0; 
      right: 110px; 
      font-family: Arial; 
      font-size: 20px; 
    }
    #speak { 
      position: absolute; 
      top: 0; 
      bottom: 0; 
      right: 0; 
      height: 100%; 
      width: 100px; 
      font-family: Arial; 
      font-size: 20px; 
    }
    #loading { 
      display: block; 
      position: absolute; 
      bottom: 10px; 
      left: 10px; 
      right: 10px; 
      height: 50px; 
      font-family: Arial; 
      font-size: 20px; 
    }
  </style>
  <!-- Azure Speech SDK for Browser -->
  <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@1.15.0/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>

  <script type="importmap">
  {
    "imports": {
      "three": "https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.module.js/+esm",
      "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.161.0/examples/jsm/",
      "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.2/modules/talkinghead.mjs"
    }
  }
  </script>
</head>
<body>
  <div id="avatar"></div>
  <div id="controls">
    <input id="text" type="text" value="Hallo! Wie geht es dir?">
    <button id="speak">Sprechen</button>
  </div>
  <div id="loading"></div>

  <script type="module">
    import { TalkingHead } from "talkinghead";

    // Replace with your Azure Speech service credentials
    const AZURE_KEY = "724b12cefed2442c9df696992b249f89";  // Replace with your Azure Speech API key
    const AZURE_REGION = "germanywestcentral";  // Replace with your Azure region
    let synthesizer;
    let head;

    document.addEventListener('DOMContentLoaded', async function () {
      // Initialize the avatar
      const nodeAvatar = document.getElementById('avatar');
      head = new TalkingHead(nodeAvatar, {
        ttsEndpoint: "",
        ttsApikey: "",
        lipsyncModules: ["en"],
        cameraView: "upper"
      });

      // Load and show the avatar
      const nodeLoading = document.getElementById('loading');
      try {
        nodeLoading.textContent = "Loading...";
        await head.showAvatar({
          url: 'https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png',
          body: 'F',
          avatarMood: 'neutral',
          lipsyncLang: 'en'
        }, (ev) => {
          if (ev.lengthComputable) {
            let val = Math.min(100, Math.round(ev.loaded / ev.total * 100));
            nodeLoading.textContent = "Loading " + val + "%";
          }
        });
        nodeLoading.style.display = 'none';
      } catch (error) {
        console.log(error);
        nodeLoading.textContent = error.toString();
      }

      // Initialize Azure Speech SDK
      const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_KEY, AZURE_REGION);
      const audioConfig = SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
      synthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);

      // Speak when clicked
      const nodeSpeak = document.getElementById('speak');
      nodeSpeak.addEventListener('click', async function () {
        const text = document.getElementById('text').value;
        if (text) {
          speakTextWithLipSync(text);
        }
      });
    });

    function speakTextWithLipSync(text) {
      const ssml = `
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xml:lang="de-DE">
          <voice name="de-DE-KatjaNeural">
            <mstts:viseme type="FacialExpression"/>
            ${text}
          </voice>
        </speak>`;

      synthesizer.speakSsmlAsync(
        ssml,
        result => {
          console.log('Speech synthesized:', result);
          head.speakText(text);  // Trigger lip-sync animation based on the text
        },
        error => {
          console.error('Error synthesizing speech:', error);
        }
      );
    }
  </script>
</body>
</html>
