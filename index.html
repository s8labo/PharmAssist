<!-- <!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Web Chat: Using Direct Line Speech</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script crossorigin="anonymous" src="https://cdn.botframework.com/botframework-webchat/latest/webchat.js"></script>
    <style>
      html,
      body {
        height: 100%;
      }

      body {
        margin: 0;
      }

      #webchat {
        height: 100%;
        width: 100%;
      }
    </style>
  </head>

  <body>
    <div id="webchat" role="main"></div>
    <script>
      (async function() {
        const adapters = await window.WebChat.createDirectLineSpeechAdapters({
            fetchCredentials: {
                region: 'germanywestcentral',
                subscriptionKey: '724b12cefed2442c9df696992b249f89'
            }
        });

        const avatarOptions = {
            botAvatarInitials: 'PA',
            userAvatarInitials: 'U'
        };

        window.WebChat.renderWebChat(
          {
            ...adapters,
            styleOptions: avatarOptions
          },
          document.getElementById('webchat')
        );

        document.querySelector('#webchat > *').focus();
      })().catch(err => console.error(err));
    </script>
  </body>
</html> -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: Arial, Helvetica, sans-serif;
        }

        h1 {
            text-align: center;
            padding: 20px;
            background-color: #f0f0f0;
        }

        #webchat {
            height: 80vh; /* Adjust the percentage as needed */
            width: 100%;
            font-size: 20px;
        }
        div.ac-container.ac-adaptiveCard .ac-textBlock p, span.ac-textRun, .ac-input.ac-textInput {
          font-size: 20px!important;
          line-height: 27px;
        }
        body, html { width:100%; height:100%; max-width: 800px; margin: auto; position: relative; background-color: dimgray; color: white; }
        #avatar { display: block; width:100%; height:100%; }
        #controls { display: block; position: absolute; top: 10px; left: 10px; right: 10px; height: 50px; }
        #text { position: absolute; width: Calc( 100% - 110px ); height: 100%; top: 0; left: 0; bottom: 0; right: 110px; font-family: Arial; font-size: 20px; }
        #speak { block; position: absolute; top: 0; bottom: 0; right: 0; height: 100%; width: 100px; font-family: Arial; font-size: 20px; }
        #loading { display: block; position: absolute; bottom: 10px; left: 10px; right: 10px; height: 50px; font-family: Arial; font-size: 20px; }
    </style>
    <script src="https://cdn.botframework.com/botframework-webchat/latest/webchat.js"></script>
    <script type="importmap">
    { "imports":
      {
        "three": "https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.module.js/+esm",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.161.0/examples/jsm/",
        "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.2/modules/talkinghead.mjs"
      }
    }
    </script>
    <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js">
    </script>

    <script type="module">
    import { TalkingHead } from "talkinghead";

    let head;
    const apiKey = '724b12cefed2442c9df696992b249f89'; // Replace with your Azure API key
    const ttsEndpoint = 'https://germanywestcentral.tts.speech.microsoft.com/cognitiveservices/v1'; // Replace with your Azure endpoint


    document.addEventListener('DOMContentLoaded', async function(e) {

      // Instantiate the class
      // NOTE: Never put your API key in a client-side code unless you know
      //       that you are the only one to have access to that code!
      const nodeAvatar = document.getElementById('avatar');
      head = new TalkingHead( nodeAvatar, {
        ttsEndpoint: ttsEndpoint,
        ttsApikey: apiKey, 
        lipsyncModules: ["en"],
        cameraView: "upper"
      });

      // Load and show the avatar
      const nodeLoading = document.getElementById('loading');
      try {
        nodeLoading.textContent = "Loading...";
        await head.showAvatar( {
          url: 'https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png',
          body: 'F',
          avatarMood: 'neutral',
          ttsLang: "de-DE",
          ttsVoice: "de-DE-KatjaNeural",
          lipsyncLang: 'de'
        }, (ev) => {
          if ( ev.lengthComputable ) {
            let val = Math.min(100,Math.round(ev.loaded/ev.total * 100 ));
            nodeLoading.textContent = "Loading " + val + "%";
          }
        });
        nodeLoading.style.display = 'none';
      } catch (error) {
        console.log(error);
        nodeLoading.textContent = error.toString();
      }

      // Function to convert text to speech using Microsoft TTS
      async function speakText(text) {
        const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(apiKey, region);
        speechConfig.speechSynthesisVoiceName = 'de-DE-KatjaNeural';  // Set to German voice
        const audioConfig = SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
        const synthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);

        // Subscribe to viseme event
        synthesizer.visemeReceived = (s, e) => {
          console.log(`Viseme received: ID: ${e.visemeId}, Offset: ${e.audioOffset / 10000}ms`);
          // Use viseme ID to trigger corresponding mouth shape on the avatar
          head.triggerViseme(e.visemeId);  // Update the avatar's mouth movement with visemeId
        };

        // Handle audio synthesis
        synthesizer.speakTextAsync(text, result => {
          if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
            console.log('Speech synthesis completed.');
          } else {
            console.error('Speech synthesis canceled: ' + result.errorDetails);
          }
        }, error => {
          console.error('Error during speech synthesis: ', error);
        });
      }

      const nodeSpeak = document.getElementById('speak');
      nodeSpeak.addEventListener('click', function () {
        const text = document.getElementById('text').value;
        if (text) {
          speakText(text);  // Use Microsoft TTS SDK
        }
      });
    });
  </script>
</head>
<body>
    <div id="avatar"></div>
      <div id="controls">
        <input id="text" type="text" value="Hi there. How are you? I'm fine.">
        <input id="speak" type="button" value="Speak">
      </div>
      <div id="loading"></div>
    <div>
        <h3>PharmAssistant f√ºr Medikationsanalysen</h3>
    </div>
    <div id="webchat" role="main">
        <div class="typing-animation"></div>
    </div>
    <script>
      (async function() {
        // const webSpeechPonyfillFactory = await window.WebChat.createCognitiveServicesSpeechServicesPonyfillFactory( {
        //     credentials: {
        //         region: 'germanywestcentral',
        //         subscriptionKey: '724b12cefed2442c9df696992b249f89'
        //     }
        // });
        const fetchSpeechServicesCredentials = {
          credentials: {
                region: 'germanywestcentral',
                subscriptionKey: '724b12cefed2442c9df696992b249f89'
            }
        }

        async function createHybridPonyfillFactory({ credentials }) {
          const speechServicesPonyfillFactory = await window.WebChat.createCognitiveServicesSpeechServicesPonyfillFactory(
            {
              credentials
            //   credentials: {
            //     region: 'germanywestcentral',
            //     subscriptionKey: '724b12cefed2442c9df696992b249f89'
            // }
            }
          );

          const webSpeechPonyfillFactory = await window.WebChat.createBrowserWebSpeechPonyfillFactory();

          return options => {
            const speechServicesPonyfill = speechServicesPonyfillFactory(options);
            const webSpeechPonyfill = webSpeechPonyfillFactory(options);

            return {
              SpeechGrammarList: webSpeechPonyfill.SpeechGrammarList,
              SpeechRecognition: webSpeechPonyfill.SpeechRecognition,

              speechSynthesis: speechServicesPonyfill.speechSynthesis,
              SpeechSynthesisUtterance: speechServicesPonyfill.SpeechSynthesisUtterance
            };
          };
        }

        const styleSet = window.WebChat.createStyleSet({
            rootHeight: '100%',
            rootWidth: '100%',
            backgroundColor: '#AEC6CF'
        });

        const avatarOptions = {
            botAvatarInitials: 'PA',
            userAvatarInitials: 'U'
        };

        // async function createSpeechRecognitionOnlyPonyfillFactory() {
        //   const speechServicesPonyfillFactory = await window.WebChat.createCognitiveServicesSpeechServicesPonyfillFactory(
        //     {
        //       credentials: {
        //         region: 'germanywestcentral',
        //         subscriptionKey: '724b12cefed2442c9df696992b249f89'
        //     }
        //     }
        //   );

        //   return options => {
        //     const speechServicesPonyfill = speechServicesPonyfillFactory(options);
        //     const webSpeechPonyfill = webSpeechPonyfillFactory(options);

        //     return {
        //       SpeechGrammarList: speechServicesPonyfill.SpeechGrammarList,
        //       SpeechRecognition: speechServicesPonyfill.SpeechRecognition,
        //       speechSynthesis: null,
        //       SpeechSynthesisUtterance: null
        //     };
        //   };
        // }

        // Function to simulate delay
        const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

        const sendMessageWithDelay = async (message) => {
            directLine.postActivity({ type: 'message', text: message });

            // Introduce a delay of 3 seconds before displaying the bot's response
            await delay(5000);

            // Fetch the activities from the conversation and display them
            const activities = await directLine.getActivity();
            activities.forEach(activity => displayActivity(activity));
        };

        const displayActivity = (activity) => {
            // Code to display the activity in your web chat interface
            // This may involve updating the DOM or using WebChat's APIs
        };

        window.WebChat.renderWebChat({
            directLine: window.WebChat.createDirectLine({
                token: 'AavR0Oh2MoQ.k8agJWGKvkYtM92I0013G-A3eObi4iVxVVGEcZFYLY4'
            }),
            // webSpeechPonyfillFactory,
            webSpeechPonyfillFactory: await createHybridPonyfillFactory({ credentials: fetchSpeechServicesCredentials }),
            enableTelemetry: false,
            styleSet,
            styleOptions: avatarOptions,
            botName: 'PharmAssistant',
            sendMessage: sendMessageWithDelay
        }, document.getElementById('webchat'));
      })().catch(err => console.error(err));
    </script>
</body>
</html>




<!-- <!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<h1>PharmAssist</h1>
<p>I'm hosted with GitHub Pages.</p> -->
<!-- <iframe src='https://webchat.botframework.com/embed/PharmAssistPublish?s=H2Ay8Zv1XgM.rshHQKc5y65ijq6pp-hrMcKKKU9BBTtiolXbhvVjVj0'  style='min-width: 400px; width: 100%; height: 100%; min-height:500px;'></iframe>
</body>
</html> --> 